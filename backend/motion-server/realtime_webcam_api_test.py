"""
ì‹¤ì‹œê°„ ì›¹ìº  ë™ì‘ ì¸ì‹ í…ŒìŠ¤íŠ¸ (API ë²„ì „)

motion-server APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë™ì‘ ì¸ì‹ í…ŒìŠ¤íŠ¸
Python 3.13ì—ì„œë„ ì‘ë™! (opencv-pythonë§Œ í•„ìš”)

ì‚¬ìš©ë²•:
    pip install opencv-python requests pillow
    python realtime_webcam_api_test.py

ì˜µì…˜:
    --url: Motion ì„œë²„ URL (ê¸°ë³¸ê°’: http://localhost:8000)
    --camera: ì¹´ë©”ë¼ ì¸ë±ìŠ¤ (ê¸°ë³¸ê°’: 0)
    --action-code: í…ŒìŠ¤íŠ¸í•  ë™ì‘ ì½”ë“œ (ê¸°ë³¸ê°’: 1)
    --fps: ìº¡ì²˜ FPS (ê¸°ë³¸ê°’: 10)

í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤:
    SPACE: í”„ë ˆì„ ìˆ˜ì§‘ ì‹œì‘/ì¤‘ì§€
    Q: ì¢…ë£Œ
    1-7: ë™ì‘ ë³€ê²½
"""

import argparse
import base64
import io
import sys
import time
from collections import deque
from typing import Deque, Optional, Dict, Any

import cv2
import requests
from PIL import Image


class RealtimeMotionAPITester:
    """ì‹¤ì‹œê°„ ì›¹ìº  ë™ì‘ ì¸ì‹ í…ŒìŠ¤í„° (API ë²„ì „)"""

    # ë™ì‘ ì½”ë“œ â†’ ì´ë¦„ ë§¤í•‘
    ACTION_NAMES = {
        1: "ì† ë°•ìˆ˜",
        2: "íŒ” ì¹˜ê¸°",
        4: "íŒ” ë»—ê¸°",
        5: "ê¸°ìš°ëš±",
        6: "ë¹„ìƒêµ¬",
        7: "ê²¨ë“œë‘ì´ë°•ìˆ˜",
        9: "ê°€ë§Œíˆ ìˆìŒ",
    }

    def __init__(
        self,
        api_url: str,
        camera_index: int = 0,
        target_action_code: int = 1,
        capture_fps: int = 10,
        frames_per_sample: int = 8,
    ):
        """
        Args:
            api_url: Motion ì„œë²„ API URL
            camera_index: ì›¹ìº  ì¸ë±ìŠ¤
            target_action_code: í…ŒìŠ¤íŠ¸í•  ë™ì‘ ì½”ë“œ
            capture_fps: í”„ë ˆì„ ìº¡ì²˜ FPS
            frames_per_sample: AI ë¶„ì„ì— ì‚¬ìš©í•  í”„ë ˆì„ ìˆ˜
        """
        self.api_url = api_url.rstrip("/") + "/api/ai/analyze"
        self.camera_index = camera_index
        self.target_action_code = target_action_code
        self.target_action_name = self.ACTION_NAMES.get(target_action_code, "ì•Œ ìˆ˜ ì—†ìŒ")
        self.capture_fps = capture_fps
        self.frames_per_sample = frames_per_sample

        # ì›¹ìº  ì´ˆê¸°í™”
        self.cap = cv2.VideoCapture(camera_index)
        if not self.cap.isOpened():
            raise RuntimeError(f"ì¹´ë©”ë¼ {camera_index}ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # í•´ìƒë„ ì„¤ì •
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        # API ì—°ê²° í…ŒìŠ¤íŠ¸
        print(f"ğŸ”Œ API ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘: {self.api_url}")
        self._test_api_connection()

        # í”„ë ˆì„ ë²„í¼
        self.frame_buffer: Deque[str] = deque(maxlen=frames_per_sample)

        # ìƒíƒœ ë³€ìˆ˜
        self.is_collecting = False
        self.last_result: Optional[Dict[str, Any]] = None
        self.last_inference_time = 0

    def _test_api_connection(self):
        """API ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            # ê°„ë‹¨í•œ ë”ë¯¸ ìš”ì²­ìœ¼ë¡œ ì—°ê²° í™•ì¸
            test_frame = self._create_test_frame()
            payload = {
                "actionCode": 1,
                "actionName": "ì† ë°•ìˆ˜",
                "frameCount": 1,
                "frames": [test_frame] * 8,
            }
            response = requests.post(
                self.api_url,
                json=payload,
                timeout=5,
            )
            if response.status_code in [200, 400]:  # 400ë„ OK (í”„ë ˆì„ì´ ë”ë¯¸ë¼ì„œ)
                print("âœ… API ì„œë²„ ì—°ê²° ì„±ê³µ!")
            else:
                print(f"âš ï¸ API ì‘ë‹µ ì½”ë“œ: {response.status_code}")
        except requests.exceptions.ConnectionError:
            print(f"âŒ API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.api_url}")
            print("motion-serverê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            sys.exit(1)
        except Exception as e:
            print(f"âš ï¸ API ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘ ì—ëŸ¬: {e}")

    def _create_test_frame(self) -> str:
        """í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ í”„ë ˆì„ ìƒì„±"""
        img = Image.new("RGB", (100, 100), color=(0, 0, 0))
        buffer = io.BytesIO()
        img.save(buffer, format="JPEG")
        buffer.seek(0)
        return base64.b64encode(buffer.read()).decode("utf-8")

    def run(self):
        """ë©”ì¸ ë£¨í”„"""
        print("\n" + "=" * 80)
        print("ğŸ¥ ì‹¤ì‹œê°„ ì›¹ìº  ë™ì‘ ì¸ì‹ ì‹œì‘! (API ë²„ì „)")
        print("=" * 80)
        print(f"ğŸ”Œ API URL: {self.api_url}")
        print(f"ğŸ“¹ ì¹´ë©”ë¼: {self.camera_index}")
        print(f"ğŸ¯ ëª©í‘œ ë™ì‘: {self.target_action_name} (ì½”ë“œ: {self.target_action_code})")
        print(f"â±ï¸ ìº¡ì²˜ FPS: {self.capture_fps}")
        print(f"ğŸ“¦ ìƒ˜í”Œ í”„ë ˆì„ ìˆ˜: {self.frames_per_sample}")
        print("\ní‚¤ë³´ë“œ ë‹¨ì¶•í‚¤:")
        print("  - SPACE: í”„ë ˆì„ ìˆ˜ì§‘ ì‹œì‘/ì¤‘ì§€")
        print("  - Q: ì¢…ë£Œ")
        print("  - 1-9: ë™ì‘ ë³€ê²½")
        print("=" * 80 + "\n")

        frame_interval = 1.0 / self.capture_fps
        last_frame_time = 0

        try:
            while True:
                ret, frame = self.cap.read()
                if not ret:
                    print("âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                    break

                # ì¢Œìš° ë°˜ì „ (ì…€ì¹´ ëª¨ë“œ)
                frame = cv2.flip(frame, 1)

                current_time = time.time()

                # FPS ì œì–´
                if self.is_collecting and (current_time - last_frame_time) >= frame_interval:
                    self._collect_frame(frame)
                    last_frame_time = current_time

                    # ë²„í¼ê°€ ë‹¤ ì°¼ìœ¼ë©´ API í˜¸ì¶œ
                    if len(self.frame_buffer) == self.frames_per_sample:
                        self._run_inference_api()
                        self.frame_buffer.clear()

                # UI ê·¸ë¦¬ê¸°
                self._draw_ui(frame)

                # í™”ë©´ í‘œì‹œ
                cv2.imshow("ì‹¤ì‹œê°„ ë™ì‘ ì¸ì‹ (API)", frame)

                # í‚¤ë³´ë“œ ì…ë ¥
                key = cv2.waitKey(1) & 0xFF
                if key == ord("q"):
                    print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤...")
                    break
                elif key == ord(" "):
                    self.is_collecting = not self.is_collecting
                    if self.is_collecting:
                        print(f"\nâ–¶ï¸ í”„ë ˆì„ ìˆ˜ì§‘ ì‹œì‘! ({self.frames_per_sample}ê°œ)")
                        self.frame_buffer.clear()
                        self.last_result = None
                    else:
                        print("\nâ¸ï¸ í”„ë ˆì„ ìˆ˜ì§‘ ì¤‘ì§€")
                elif key in [ord("1"), ord("2"), ord("4"), ord("5"), ord("6"), ord("7"), ord("9")]:
                    code = int(chr(key))
                    if code in self.ACTION_NAMES:
                        self._change_target_action(code)

        finally:
            self.cap.release()
            cv2.destroyAllWindows()

    def _collect_frame(self, frame):
        """í”„ë ˆì„ì„ Base64ë¡œ ë³€í™˜í•˜ì—¬ ë²„í¼ì— ì¶”ê°€"""
        # OpenCV BGR â†’ RGB
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # PIL Imageë¡œ ë³€í™˜
        pil_image = Image.fromarray(rgb_frame)

        # JPEG ì¸ì½”ë”© í›„ Base64 ë³€í™˜
        buffer = io.BytesIO()
        pil_image.save(buffer, format="JPEG", quality=85)
        buffer.seek(0)
        base64_str = base64.b64encode(buffer.read()).decode("utf-8")

        self.frame_buffer.append(base64_str)

    def _run_inference_api(self):
        """API í˜¸ì¶œí•˜ì—¬ AI ì¶”ë¡ """
        start_time = time.time()

        try:
            print(f"\nğŸ” AI ë¶„ì„ ì‹œì‘... (í”„ë ˆì„: {len(self.frame_buffer)}ê°œ)")

            payload = {
                "actionCode": self.target_action_code,
                "actionName": self.target_action_name,
                "frameCount": len(self.frame_buffer),
                "frames": list(self.frame_buffer),
            }

            response = requests.post(
                self.api_url,
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=30,
            )

            self.last_inference_time = (time.time() - start_time) * 1000

            if response.status_code == 200:
                result = response.json()
                self.last_result = result
                self._print_result(result)
            else:
                error_detail = response.json().get("detail", "Unknown error")
                print(f"âŒ API ì—ëŸ¬ (HTTP {response.status_code}): {error_detail}")
                self.last_result = None

        except requests.exceptions.Timeout:
            print(f"âŒ íƒ€ì„ì•„ì›ƒ: API ì‘ë‹µì´ 30ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
            self.last_result = None
        except requests.exceptions.ConnectionError:
            print(f"âŒ ì—°ê²° ì‹¤íŒ¨: API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.last_result = None
        except Exception as e:
            print(f"âŒ ì˜ˆì™¸ ë°œìƒ: {e}")
            self.last_result = None

    def _print_result(self, result: Dict[str, Any]):
        """ì¶”ë¡  ê²°ê³¼ ì½˜ì†” ì¶œë ¥"""
        score_emoji = ["âŒ", "âš ï¸", "âœ…", "ğŸ¯"]

        judgment = result.get("judgment", 0)
        predicted_label = result.get("predictedLabel", "N/A")
        confidence = result.get("confidence", 0) * 100
        target_prob = result.get("targetProbability")

        print("\n" + "=" * 80)
        print("ğŸ¯ AI íŒì • ê²°ê³¼")
        print("=" * 80)
        print(f"  ëª©í‘œ ë™ì‘: {self.target_action_name} (ì½”ë“œ: {self.target_action_code})")
        print(f"  ì˜ˆì¸¡ ë™ì‘: {predicted_label}")
        print(f"  ì˜ˆì¸¡ ì‹ ë¢°ë„: {confidence:.1f}%")

        if target_prob is not None:
            print(f"  ëª©í‘œ í™•ë¥ : {target_prob * 100:.1f}%")

        print(f"\n  ìµœì¢… ì ìˆ˜: {judgment}ì  {score_emoji[judgment]}")

        decode_ms = result.get("decodeTimeMs", 0)
        pose_ms = result.get("poseTimeMs", 0)
        inference_ms = result.get("inferenceTimeMs", 0)
        total_ms = decode_ms + pose_ms + inference_ms

        print(f"\n  ì²˜ë¦¬ ì‹œê°„: {total_ms:.0f}ms")
        print(f"    - ë””ì½”ë”©: {decode_ms:.0f}ms")
        print(f"    - Pose ì¶”ì¶œ: {pose_ms:.0f}ms")
        print(f"    - AI ì¶”ë¡ : {inference_ms:.0f}ms")
        print(f"  ë„¤íŠ¸ì›Œí¬ ì™•ë³µ: {self.last_inference_time:.0f}ms")
        print("=" * 80 + "\n")

    def _draw_ui(self, frame):
        """í™”ë©´ì— UI ê·¸ë¦¬ê¸°"""
        height, width = frame.shape[:2]

        # ë°˜íˆ¬ëª… ë°°ê²½
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (width - 10, 220), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)

        y_offset = 40
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        thickness = 2

        # ìˆ˜ì§‘ ìƒíƒœ
        status_text = "ìˆ˜ì§‘ ì¤‘..." if self.is_collecting else "ëŒ€ê¸° ì¤‘ (SPACEë¡œ ì‹œì‘)"
        status_color = (0, 255, 0) if self.is_collecting else (100, 100, 100)
        cv2.putText(frame, status_text, (20, y_offset), font, font_scale, status_color, thickness)
        y_offset += 35

        # ëª©í‘œ ë™ì‘
        cv2.putText(
            frame,
            f"ëª©í‘œ: {self.target_action_name} (ì½”ë“œ: {self.target_action_code})",
            (20, y_offset),
            font,
            0.6,
            (255, 255, 255),
            1,
        )
        y_offset += 30

        # ë²„í¼ ìƒíƒœ
        buffer_text = f"ë²„í¼: {len(self.frame_buffer)}/{self.frames_per_sample}"
        cv2.putText(frame, buffer_text, (20, y_offset), font, 0.6, (255, 255, 255), 1)
        y_offset += 35

        # ë§ˆì§€ë§‰ ê²°ê³¼
        if self.last_result:
            judgment = self.last_result.get("judgment", 0)
            predicted_label = self.last_result.get("predictedLabel", "N/A")
            confidence = self.last_result.get("confidence", 0) * 100
            target_prob = self.last_result.get("targetProbability")

            # íŒì •
            judgment_color = self._get_judgment_color(judgment)
            judgment_text = f"íŒì •: {judgment}ì "
            cv2.putText(frame, judgment_text, (20, y_offset), font, font_scale, judgment_color, thickness)
            y_offset += 30

            # ì˜ˆì¸¡ ë™ì‘
            predicted_text = f"ì˜ˆì¸¡: {predicted_label}"
            cv2.putText(frame, predicted_text, (20, y_offset), font, 0.6, (255, 255, 255), 1)
            y_offset += 25

            # ì‹ ë¢°ë„
            confidence_text = f"ì‹ ë¢°ë„: {confidence:.1f}%"
            cv2.putText(frame, confidence_text, (20, y_offset), font, 0.6, (255, 255, 255), 1)
            y_offset += 25

            # ëª©í‘œ í™•ë¥ 
            if target_prob is not None:
                target_prob_text = f"ëª©í‘œí™•ë¥ : {target_prob * 100:.1f}%"
                cv2.putText(frame, target_prob_text, (20, y_offset), font, 0.6, (255, 255, 255), 1)

        # í•˜ë‹¨ ë„ì›€ë§
        help_text = "Q: ì¢…ë£Œ | SPACE: ì‹œì‘/ì¤‘ì§€ | 1-9: ë™ì‘ë³€ê²½"
        cv2.putText(
            frame,
            help_text,
            (20, height - 20),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (200, 200, 200),
            1,
        )

    def _get_judgment_color(self, judgment: int) -> tuple:
        """íŒì • ì ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒ (BGR)"""
        colors = {
            0: (0, 0, 255),  # ë¹¨ê°•
            1: (0, 165, 255),  # ì£¼í™©
            2: (0, 255, 255),  # ë…¸ë‘
            3: (0, 255, 0),  # ì´ˆë¡
        }
        return colors.get(judgment, (255, 255, 255))

    def _change_target_action(self, action_code: int):
        """ëª©í‘œ ë™ì‘ ë³€ê²½"""
        self.target_action_code = action_code
        self.target_action_name = self.ACTION_NAMES[action_code]
        self.last_result = None
        print(f"\nğŸ¯ ëª©í‘œ ë™ì‘ ë³€ê²½: {self.target_action_name} (ì½”ë“œ: {action_code})")


def main():
    parser = argparse.ArgumentParser(description="ì‹¤ì‹œê°„ ì›¹ìº  ë™ì‘ ì¸ì‹ (API ë²„ì „)")
    parser.add_argument(
        "--url",
        type=str,
        default="http://localhost:8000",
        help="Motion ì„œë²„ URL (ê¸°ë³¸ê°’: http://localhost:8000)",
    )
    parser.add_argument(
        "--camera",
        type=int,
        default=0,
        help="ì¹´ë©”ë¼ ì¸ë±ìŠ¤ (ê¸°ë³¸ê°’: 0)",
    )
    parser.add_argument(
        "--action-code",
        type=int,
        default=1,
        help="í…ŒìŠ¤íŠ¸í•  ë™ì‘ ì½”ë“œ (ê¸°ë³¸ê°’: 1)",
    )
    parser.add_argument(
        "--fps",
        type=int,
        default=10,
        help="ìº¡ì²˜ FPS (ê¸°ë³¸ê°’: 10)",
    )

    args = parser.parse_args()

    try:
        tester = RealtimeMotionAPITester(
            api_url=args.url,
            camera_index=args.camera,
            target_action_code=args.action_code,
            capture_fps=args.fps,
        )
        tester.run()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
