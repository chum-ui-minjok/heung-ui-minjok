"""Brandnew ëª¨ì…˜ ì¶”ë¡  ì„œë¹„ìŠ¤ - ìƒˆë¡œìš´ ëª¨ë¸ ì „ìš©."""

from __future__ import annotations

import logging
import os
from functools import lru_cache
from pathlib import Path
from typing import Sequence

import numpy as np
import torch

from app.services.inference import (
    InferenceResult,
    MotionGCNCNN,
    PoseExtractor,
)

LOGGER = logging.getLogger(__name__)


class BrandnewMotionInferenceService:
    """
    Brandnew ëª¨ë¸ ì „ìš© ì¶”ë¡  ì„œë¹„ìŠ¤

    ê¸°ì¡´ ëª¨ë¸ê³¼ í´ë˜ìŠ¤ ë§¤í•‘ì´ ë‹¤ë¥´ë¯€ë¡œ ë³„ë„ êµ¬í˜„ í•„ìš”:

    Brandnew ëª¨ë¸ í´ë˜ìŠ¤ ìˆœì„œ:
      0: CLAP, 1: ELBOW, 2: EXIT, 3: STAY, 4: STRETCH, 5: TILT, 6: UNDERARM

    ê¸°ì¡´ ëª¨ë¸ í´ë˜ìŠ¤ ìˆœì„œ:
      0: CLAP, 1: ELBOW, 2: STRETCH, 3: TILT, 4: EXIT, 5: UNDERARM, 6: STAY
    """

    def __init__(self, model_path: Path, device: str | None = None) -> None:
        checkpoint = torch.load(model_path, map_location="cpu", weights_only=False)
        args = checkpoint.get("args", {})
        class_mapping = checkpoint.get("class_mapping", {})

        if device:
            requested = torch.device(device)
            if requested.type == "cuda" and not torch.cuda.is_available():
                raise RuntimeError("CUDA ì¥ì¹˜ê°€ ìš”ì²­ë˜ì—ˆì§€ë§Œ ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            self.device = requested
        else:
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        LOGGER.info("Brandnew model inference device: %s", self.device)
        self.frames_per_sample = int(args.get("frames_per_sample", 8))
        self.class_mapping = {label.upper(): index for label, index in class_mapping.items()}
        self.id_to_label = {index: label for label, index in self.class_mapping.items()}

        LOGGER.info("Brandnew model class mapping: %s", self.id_to_label)

        gcn_hidden_dims = args.get("gcn_hidden_dims", [64, 128])
        temporal_channels = args.get("temporal_channels", [128, 256])
        dropout = float(args.get("dropout", 0.3))

        self.model = MotionGCNCNN(
            num_nodes=checkpoint["model_state_dict"]["gcn_layers.0.adjacency"].shape[0],
            input_dim=checkpoint["model_state_dict"]["gcn_layers.0.linear.weight"].shape[1],
            gcn_hidden_dims=gcn_hidden_dims,
            temporal_channels=temporal_channels,
            num_classes=len(self.class_mapping),
            dropout=dropout,
        )
        self.model.load_state_dict(checkpoint["model_state_dict"])
        self.model.to(self.device)
        self.model.eval()

        self.pose_extractor = PoseExtractor()

        # Brandnew ëª¨ë¸ìš© ë§¤í•‘
        # DB actionCode â†’ Model class_index
        self.ACTION_CODE_TO_CLASS_INDEX = {
            1: 0,  # ì† ë°•ìˆ˜ â†’ CLAP
            2: 1,  # íŒ” ì¹˜ê¸° â†’ ELBOW
            4: 4,  # íŒ” ë»—ê¸° â†’ STRETCH
            5: 5,  # ê¸°ìš°ëš± â†’ TILT
            6: 2,  # ë¹„ìƒêµ¬ â†’ EXIT
            7: 6,  # ê²¨ë“œë‘ì´ë°•ìˆ˜ â†’ UNDERARM
            9: 3,  # ê°€ë§Œíˆ ìˆìŒ â†’ STAY
        }

        # Model class_index â†’ DB actionCode
        self.CLASS_INDEX_TO_ACTION_CODE = {
            0: 1,  # CLAP â†’ ì† ë°•ìˆ˜
            1: 2,  # ELBOW â†’ íŒ” ì¹˜ê¸°
            2: 6,  # EXIT â†’ ë¹„ìƒêµ¬
            3: 9,  # STAY â†’ ê°€ë§Œíˆ ìˆìŒ
            4: 4,  # STRETCH â†’ íŒ” ë»—ê¸°
            5: 5,  # TILT â†’ ê¸°ìš°ëš±
            6: 7,  # UNDERARM â†’ ê²¨ë“œë‘ì´ë°•ìˆ˜
        }

    def predict(
        self,
        frames: Sequence[str],
        target_action_name: str | None = None,
        target_action_code: int | None = None,
    ) -> InferenceResult:
        """í”„ë ˆì„ ì‹œí€€ìŠ¤ë¥¼ ë°›ì•„ ë™ì‘ ì˜ˆì¸¡ ìˆ˜í–‰"""
        if not frames:
            raise ValueError("í”„ë ˆì„ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

        # ê¸°ì¡´ inference.pyì˜ ë¡œì§ ì¬ì‚¬ìš©
        from app.services.inference import MotionInferenceService

        # ì„ì‹œ ì„œë¹„ìŠ¤ ìƒì„± (ì „ì²˜ë¦¬ìš©)
        temp_service = MotionInferenceService.__new__(MotionInferenceService)
        temp_service.frames_per_sample = self.frames_per_sample
        temp_service.pose_extractor = self.pose_extractor
        temp_service.device = self.device

        sampled_frames = temp_service._sample_frames(frames, self.frames_per_sample)
        keypoint_sequence, decode_time_s, pose_time_s = temp_service._frames_to_keypoints(
            sampled_frames
        )

        LOGGER.info("ğŸ” Brandnew - Keypoint sequence shape: %s", keypoint_sequence.shape)

        input_tensor = torch.from_numpy(keypoint_sequence).unsqueeze(0)
        input_tensor = input_tensor.to(self.device)

        with torch.no_grad():
            from time import perf_counter

            inference_start = perf_counter()
            logits = self.model(input_tensor)
            inference_time_ms = (perf_counter() - inference_start) * 1000
            probabilities = torch.softmax(logits, dim=-1).cpu().numpy()[0]

            LOGGER.info("ğŸ” Brandnew - Logits: %s", logits.cpu().numpy()[0])
            LOGGER.info("ğŸ” Brandnew - Probabilities: %s", probabilities)
            LOGGER.info("ğŸ” Brandnew - Class mapping: %s", self.id_to_label)

        decode_time_ms = decode_time_s * 1000
        pose_time_ms = pose_time_s * 1000

        best_idx = int(np.argmax(probabilities))
        predicted_label = self.id_to_label.get(best_idx, "UNKNOWN")
        confidence = float(probabilities[best_idx])

        target_index = self._resolve_target_index(target_action_name, target_action_code)
        target_probability: float | None = None
        if target_index is not None and 0 <= target_index < len(probabilities):
            target_probability = float(probabilities[target_index])
            judgment = self._score_by_probability(target_probability)
        else:
            judgment = self._fallback_score(predicted_label, confidence, target_action_name)

        total_time_ms = decode_time_ms + pose_time_ms + inference_time_ms
        LOGGER.info(
            "ğŸ¯ Brandnew AI íŒì • - ëª©í‘œ=%s(code=%s), ì˜ˆì¸¡=%s(%.1f%%), "
            "ëª©í‘œí™•ë¥ =%.1f%%, ì ìˆ˜=%dì  | â±ï¸ ì´=%.0fms",
            target_action_name,
            target_action_code,
            predicted_label,
            confidence * 100,
            (target_probability * 100) if target_probability else 0,
            judgment,
            total_time_ms,
        )

        # actionCode ë³€í™˜ (Brandnew ë§¤í•‘ ì‚¬ìš©)
        if target_action_code is not None:
            resolved_action_code = target_action_code
        else:
            resolved_action_code = self.CLASS_INDEX_TO_ACTION_CODE.get(best_idx, best_idx + 1)

        return InferenceResult(
            predicted_label=predicted_label,
            confidence=confidence,
            judgment=judgment,
            action_code=resolved_action_code,
            decode_time_ms=decode_time_ms,
            pose_time_ms=pose_time_ms,
            inference_time_ms=inference_time_ms,
            target_probability=target_probability,
        )

    def _resolve_target_index(
        self, action_name: str | None, action_code: int | None
    ) -> int | None:
        """ëª©í‘œ ë™ì‘ì„ ëª¨ë¸ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜"""
        if action_code is not None:
            model_index = self.ACTION_CODE_TO_CLASS_INDEX.get(action_code)
            if model_index is not None and model_index in self.id_to_label:
                return model_index

        if action_name:
            key = action_name.strip().upper()
            return self.class_mapping.get(key)

        return None

    @staticmethod
    def _score_by_probability(probability: float) -> int:
        """í™•ë¥  ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°"""
        if probability >= 0.90:
            return 3
        if probability >= 0.75:
            return 2
        if probability >= 0.60:
            return 1
        return 0

    def _fallback_score(
        self, predicted_label: str, confidence: float, target_action: str | None
    ) -> int:
        """ëª©í‘œ í™•ë¥ ì´ ì—†ì„ ë•Œ í´ë°± ì ìˆ˜ ê³„ì‚°"""
        if not target_action:
            if confidence >= 0.90:
                return 3
            if confidence >= 0.75:
                return 2
            if confidence >= 0.60:
                return 1
            return 0

        target_key = target_action.strip().upper()
        predicted_key = predicted_label.strip().upper()

        if target_key == predicted_key:
            if confidence >= 0.90:
                return 3
            if confidence >= 0.75:
                return 2
            if confidence >= 0.60:
                return 1
            return 0
        else:
            return 0


@lru_cache(maxsize=1)
def get_brandnew_inference_service() -> BrandnewMotionInferenceService:
    """Brandnew ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì¶”ë¡  ì„œë¹„ìŠ¤ ë°˜í™˜."""
    model_path = Path(__file__).resolve().parent.parent / "brandnewTrain" / "checkpoints" / "brandnew_model_v1.pt"

    if not model_path.exists():
        raise FileNotFoundError(f"Brandnew ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

    device_override = os.getenv("MOTION_INFERENCE_DEVICE")
    LOGGER.info("Loading brandnew model from: %s", model_path)

    return BrandnewMotionInferenceService(model_path=model_path, device=device_override)
