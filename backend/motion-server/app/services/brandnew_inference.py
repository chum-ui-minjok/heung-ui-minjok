"""Brandnew ëª¨ì…˜ ì¶”ë¡  ì„œë¹„ìŠ¤ - ìƒˆë¡œìš´ ëª¨ë¸ ì „ìš©."""

from __future__ import annotations

import logging
import os
from functools import lru_cache
from pathlib import Path
from typing import Sequence

import numpy as np
import torch

from app.services.inference import (
    InferenceResult,
    MotionGCNCNN,
    PoseExtractor,
)

LOGGER = logging.getLogger(__name__)


class BrandnewMotionInferenceService:
    """
    Brandnew ëª¨ë¸ ì „ìš© ì¶”ë¡  ì„œë¹„ìŠ¤

    ê¸°ì¡´ ëª¨ë¸ê³¼ í´ë˜ìŠ¤ ë§¤í•‘ì´ ë‹¤ë¥´ë¯€ë¡œ ë³„ë„ êµ¬í˜„ í•„ìš”:

    Brandnew ëª¨ë¸ í´ë˜ìŠ¤ ìˆœì„œ:
      0: CLAP, 1: ELBOW, 2: EXIT, 3: STAY, 4: STRETCH, 5: TILT, 6: UNDERARM

    ê¸°ì¡´ ëª¨ë¸ í´ë˜ìŠ¤ ìˆœì„œ:
      0: CLAP, 1: ELBOW, 2: STRETCH, 3: TILT, 4: EXIT, 5: UNDERARM, 6: STAY
    """

    def __init__(self, model_path: Path, device: str | None = None) -> None:
        checkpoint = torch.load(model_path, map_location="cpu", weights_only=False)
        args = checkpoint.get("args", {})
        class_mapping = checkpoint.get("class_mapping", {})

        if device:
            requested = torch.device(device)
            if requested.type == "cuda" and not torch.cuda.is_available():
                raise RuntimeError("CUDA ì¥ì¹˜ê°€ ìš”ì²­ë˜ì—ˆì§€ë§Œ ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            self.device = requested
        else:
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        LOGGER.info("Brandnew model inference device: %s", self.device)
        self.frames_per_sample = int(args.get("frames_per_sample", 8))
        self.class_mapping = {label.upper(): index for label, index in class_mapping.items()}
        self.id_to_label = {index: label for label, index in self.class_mapping.items()}

        LOGGER.info("Brandnew model class mapping: %s", self.id_to_label)

        gcn_hidden_dims = args.get("gcn_hidden_dims", [64, 128])
        temporal_channels = args.get("temporal_channels", [128, 256])
        dropout = float(args.get("dropout", 0.3))

        self.model = MotionGCNCNN(
            num_nodes=checkpoint["model_state_dict"]["gcn_layers.0.adjacency"].shape[0],
            input_dim=checkpoint["model_state_dict"]["gcn_layers.0.linear.weight"].shape[1],
            gcn_hidden_dims=gcn_hidden_dims,
            temporal_channels=temporal_channels,
            num_classes=len(self.class_mapping),
            dropout=dropout,
        )
        self.model.load_state_dict(checkpoint["model_state_dict"])
        self.model.to(self.device)
        self.model.eval()

        self.pose_extractor = PoseExtractor()

        # Brandnew ëª¨ë¸ìš© ë§¤í•‘
        # DB actionCode â†’ Model class_index
        self.ACTION_CODE_TO_CLASS_INDEX = {
            1: 0,  # ì† ë°•ìˆ˜ â†’ CLAP
            2: 1,  # íŒ” ì¹˜ê¸° â†’ ELBOW
            4: 4,  # íŒ” ë»—ê¸° â†’ STRETCH
            5: 5,  # ê¸°ìš°ëš± â†’ TILT
            6: 2,  # ë¹„ìƒêµ¬ â†’ EXIT
            7: 6,  # ê²¨ë“œë‘ì´ë°•ìˆ˜ â†’ UNDERARM
            9: 3,  # ê°€ë§Œíˆ ìˆìŒ â†’ STAY
        }

        # Model class_index â†’ DB actionCode
        self.CLASS_INDEX_TO_ACTION_CODE = {
            0: 1,  # CLAP â†’ ì† ë°•ìˆ˜
            1: 2,  # ELBOW â†’ íŒ” ì¹˜ê¸°
            2: 6,  # EXIT â†’ ë¹„ìƒêµ¬
            3: 9,  # STAY â†’ ê°€ë§Œíˆ ìˆìŒ
            4: 4,  # STRETCH â†’ íŒ” ë»—ê¸°
            5: 5,  # TILT â†’ ê¸°ìš°ëš±
            6: 7,  # UNDERARM â†’ ê²¨ë“œë‘ì´ë°•ìˆ˜
        }

    def predict(
        self,
        frames: Sequence[str],
        target_action_name: str | None = None,
        target_action_code: int | None = None,
    ) -> InferenceResult:
        """í”„ë ˆì„ ì‹œí€€ìŠ¤ë¥¼ ë°›ì•„ ë™ì‘ ì˜ˆì¸¡ ìˆ˜í–‰"""
        if not frames:
            raise ValueError("í”„ë ˆì„ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

        # ì „ì²˜ë¦¬: í•™ìŠµê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì „ì²´ ì‹œí€€ìŠ¤ ì •ê·œí™”
        sampled_frames = self._sample_frames(frames, self.frames_per_sample)
        keypoint_sequence, decode_time_s, pose_time_s = self._frames_to_keypoints_corrected(
            sampled_frames
        )

        LOGGER.info("ğŸ” Brandnew - Keypoint sequence shape: %s", keypoint_sequence.shape)

        input_tensor = torch.from_numpy(keypoint_sequence).unsqueeze(0)
        input_tensor = input_tensor.to(self.device)

        with torch.no_grad():
            from time import perf_counter

            inference_start = perf_counter()
            logits = self.model(input_tensor)
            inference_time_ms = (perf_counter() - inference_start) * 1000
            probabilities = torch.softmax(logits, dim=-1).cpu().numpy()[0]

            LOGGER.info("ğŸ” Brandnew - Logits: %s", logits.cpu().numpy()[0])
            LOGGER.info("ğŸ” Brandnew - Probabilities: %s", probabilities)
            LOGGER.info("ğŸ” Brandnew - Class mapping: %s", self.id_to_label)

        decode_time_ms = decode_time_s * 1000
        pose_time_ms = pose_time_s * 1000

        best_idx = int(np.argmax(probabilities))
        predicted_label = self.id_to_label.get(best_idx, "UNKNOWN")
        confidence = float(probabilities[best_idx])

        target_index = self._resolve_target_index(target_action_name, target_action_code)
        target_probability: float | None = None
        if target_index is not None and 0 <= target_index < len(probabilities):
            target_probability = float(probabilities[target_index])
            judgment = self._score_by_probability(target_probability)
        else:
            judgment = self._fallback_score(predicted_label, confidence, target_action_name)

        total_time_ms = decode_time_ms + pose_time_ms + inference_time_ms
        LOGGER.info(
            "ğŸ¯ Brandnew AI íŒì • - ëª©í‘œ=%s(code=%s), ì˜ˆì¸¡=%s(%.1f%%), "
            "ëª©í‘œí™•ë¥ =%.1f%%, ì ìˆ˜=%dì  | â±ï¸ ì´=%.0fms",
            target_action_name,
            target_action_code,
            predicted_label,
            confidence * 100,
            (target_probability * 100) if target_probability else 0,
            judgment,
            total_time_ms,
        )

        # actionCode ë³€í™˜ (Brandnew ë§¤í•‘ ì‚¬ìš©)
        if target_action_code is not None:
            resolved_action_code = target_action_code
        else:
            resolved_action_code = self.CLASS_INDEX_TO_ACTION_CODE.get(best_idx, best_idx + 1)

        return InferenceResult(
            predicted_label=predicted_label,
            confidence=confidence,
            judgment=judgment,
            action_code=resolved_action_code,
            decode_time_ms=decode_time_ms,
            pose_time_ms=pose_time_ms,
            inference_time_ms=inference_time_ms,
            target_probability=target_probability,
        )

    def _resolve_target_index(
        self, action_name: str | None, action_code: int | None
    ) -> int | None:
        """ëª©í‘œ ë™ì‘ì„ ëª¨ë¸ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜"""
        if action_code is not None:
            model_index = self.ACTION_CODE_TO_CLASS_INDEX.get(action_code)
            if model_index is not None and model_index in self.id_to_label:
                return model_index

        if action_name:
            key = action_name.strip().upper()
            return self.class_mapping.get(key)

        return None

    @staticmethod
    def _score_by_probability(probability: float) -> int:
        """í™•ë¥  ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°"""
        if probability >= 0.90:
            return 3
        if probability >= 0.75:
            return 2
        if probability >= 0.60:
            return 1
        return 0

    def _fallback_score(
        self, predicted_label: str, confidence: float, target_action: str | None
    ) -> int:
        """ëª©í‘œ í™•ë¥ ì´ ì—†ì„ ë•Œ í´ë°± ì ìˆ˜ ê³„ì‚°"""
        if not target_action:
            if confidence >= 0.90:
                return 3
            if confidence >= 0.75:
                return 2
            if confidence >= 0.60:
                return 1
            return 0

        target_key = target_action.strip().upper()
        predicted_key = predicted_label.strip().upper()

        if target_key == predicted_key:
            if confidence >= 0.90:
                return 3
            if confidence >= 0.75:
                return 2
            if confidence >= 0.60:
                return 1
            return 0
        else:
            return 0

    def _frames_to_keypoints_corrected(self, frames: Sequence[str]):
        """
        í”„ë ˆì„ì„ í‚¤í¬ì¸íŠ¸ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜ (í•™ìŠµê³¼ ë™ì¼í•œ ì •ê·œí™” ì‚¬ìš©)

        í•µì‹¬ ì°¨ì´ì :
        - ê¸°ì¡´: ê° í”„ë ˆì„ë³„ë¡œ ê°œë³„ ì •ê·œí™”
        - ìˆ˜ì •: ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ ëª¨ì•„ì„œ í•œ ë²ˆì— ì •ê·œí™” (í•™ìŠµê³¼ ë™ì¼)
        """
        import base64
        from io import BytesIO
        from time import perf_counter
        from PIL import Image, ImageOps

        raw_landmarks_list = []
        decode_elapsed = 0.0
        pose_elapsed = 0.0
        valid_count = 0
        total_count = 0

        for encoded in frames:
            total_count += 1

            # ì´ë¯¸ì§€ ë””ì½”ë”©
            decode_start = perf_counter()
            try:
                image_data = base64.b64decode(encoded)
            except Exception as exc:
                raise ValueError("Base64 ë””ì½”ë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") from exc

            with Image.open(BytesIO(image_data)) as img:
                img = ImageOps.exif_transpose(img)
                if img is None:
                    img = Image.open(BytesIO(image_data))
                rgb_image = img.convert("RGB")
                image_np = np.array(rgb_image)

            decode_elapsed += perf_counter() - decode_start

            # Pose ì¶”ì¶œ (raw, ì •ê·œí™” ì•ˆ í•¨)
            pose_start = perf_counter()
            results = self.pose_extractor._pose.process(image_np)
            pose_elapsed += perf_counter() - pose_start

            if not results.pose_landmarks:
                # Person not detected - skip this frame
                continue

            # 33 landmarks ì¶”ì¶œ (raw)
            landmarks = results.pose_landmarks.landmark
            all_coords = np.array(
                [(lm.x, lm.y) for lm in landmarks],
                dtype=np.float32
            )  # (33, 2)

            raw_landmarks_list.append(all_coords)
            valid_count += 1

        # ìµœì†Œ í”„ë ˆì„ ì²´í¬
        MIN_VALID_FRAMES = 5
        if valid_count < MIN_VALID_FRAMES:
            raise ValueError(
                f"ìœ íš¨í•œ ë™ì‘ í”„ë ˆì„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ ({valid_count}/{total_count}ê°œ). "
                f"ì¹´ë©”ë¼ì— ì „ì‹ ì´ ë³´ì´ë„ë¡ í•´ì£¼ì„¸ìš”."
            )

        LOGGER.info(
            "ğŸ“¹ Brandnew - í”„ë ˆì„ ë¶„ì„: ìœ íš¨=%dê°œ, ì „ì²´=%dê°œ",
            valid_count, total_count
        )

        # (T, 33, 2) í˜•íƒœë¡œ ìŠ¤íƒ
        raw_sequence = np.stack(raw_landmarks_list, axis=0)

        # ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ í•œ ë²ˆì— ì •ê·œí™” (train_gcn_cnn.pyì™€ ë™ì¼)
        normalized_sequence = self._normalize_sequence(raw_sequence)

        decode_time_s = decode_elapsed
        pose_time_s = pose_elapsed

        return normalized_sequence, decode_time_s, pose_time_s

    @staticmethod
    def _normalize_sequence(landmarks_sequence: np.ndarray) -> np.ndarray:
        """
        ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ ì •ê·œí™” (train_gcn_cnn.pyì˜ normalize_landmarksì™€ ë™ì¼)

        Args:
            landmarks_sequence: (T, 33, 2) raw landmarks

        Returns:
            (T, 22, 2) normalized body keypoints
        """
        # Step 1: x, y ì¢Œí‘œë§Œ ì‚¬ìš©
        coords = landmarks_sequence[..., :2]  # (T, 33, 2)

        # Step 2: Pelvis (hip í‰ê· )ë¡œ ì¤‘ì‹¬ ì •ë ¬
        HIP_INDICES = (23, 24)
        pelvis = (coords[:, HIP_INDICES[0], :] + coords[:, HIP_INDICES[1], :]) / 2.0  # (T, 2)
        coords = coords - pelvis[:, None, :]  # (T, 33, 2)

        # Step 3: ì‹ ì²´ ëœë“œë§ˆí¬ë§Œ ì„ íƒ (11-32)
        USED_LANDMARK_INDICES = list(range(11, 33))
        body_coords = coords[:, USED_LANDMARK_INDICES, :]  # (T, 22, 2)

        # Step 4: ì „ì²´ ì‹œí€€ìŠ¤ì˜ max normìœ¼ë¡œ ì •ê·œí™” (í•µì‹¬!)
        max_range = np.max(np.linalg.norm(body_coords, axis=-1, ord=2))
        if max_range < 1e-6:
            max_range = 1.0
        body_coords = body_coords / max_range

        return body_coords.astype(np.float32)

    def _sample_frames(self, frames: Sequence[str], target_count: int):
        """í”„ë ˆì„ ìƒ˜í”Œë§"""
        if len(frames) == target_count:
            return list(frames)

        if len(frames) < target_count:
            padding = [frames[-1]] * (target_count - len(frames))
            return list(frames) + padding

        indices = np.linspace(0, len(frames) - 1, target_count).astype(int)
        return [frames[i] for i in indices]


@lru_cache(maxsize=1)
def get_brandnew_inference_service() -> BrandnewMotionInferenceService:
    """Brandnew ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì¶”ë¡  ì„œë¹„ìŠ¤ ë°˜í™˜."""
    model_path = Path(__file__).resolve().parent.parent / "brandnewTrain" / "checkpoints" / "brandnew_model_v1.pt"

    if not model_path.exists():
        raise FileNotFoundError(f"Brandnew ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

    device_override = os.getenv("MOTION_INFERENCE_DEVICE")
    LOGGER.info("Loading brandnew model from: %s", model_path)

    return BrandnewMotionInferenceService(model_path=model_path, device=device_override)
