/* @ts-nocheck */
import { useState, useRef, useCallback } from 'react';
import { type Frame } from '@/types';
import { GAME_CONFIG, calculateExpectedFrames } from '@/utils';

interface UseFrameCaptureProps {
  videoRef: React.RefObject<HTMLVideoElement | null>;
  audioRef: React.RefObject<HTMLAudioElement | null>;
  canvasRef: React.RefObject<HTMLCanvasElement | null>;
}

interface UseFrameCaptureReturn {
  isCapturing: boolean;
  frameBuffer: Frame[];
  startCapture: (startTime: number, endTime: number) => void;
  stopCapture: () => Frame[];
}

export const useFrameCapture = ({
  videoRef,
  audioRef,
  canvasRef,
}: UseFrameCaptureProps): UseFrameCaptureReturn => {
  const captureEpochRef = useRef(0); // ì„¸ê·¸ë¨¼íŠ¸(ìº¡ì²˜ ì„¸ì…˜) ì‹ë³„ìš©
    // âœ… ìˆ˜ì • (UIìš© stateëŠ” ìœ ì§€í•˜ë˜, ë™ì‘ ì œì–´ëŠ” refë¡œ)
  const [isCapturing, setIsCapturing] = useState(false); // UI í‘œì‹œìš©
  const isCapturingRef = useRef(false);                   // ì‹¤ì œ ì œì–´ìš©
    // âœ… ìˆ˜ì •
  const [frameBuffer, setFrameBuffer] = useState<Frame[]>([]); // UIìš©
  const frameBufferRef = useRef<Frame[]>([]);                  // ì‹¤ë°ì´í„°
  
  const captureStartTimeRef = useRef<number>(0);
  const frameCountRef = useRef<number>(0);
  const expectedFramesRef = useRef<number>(0);
  const encodingRef = useRef<boolean>(false);
  const animationFrameIdRef = useRef<number | null>(null);
  /**
   * í”„ë ˆì„ ìº¡ì²˜ ì¤‘ì§€
   */
 // âœ… ìˆ˜ì •
    const stopCapture = useCallback((): Frame[] => {
      // 1) ë“¤ì–´ì˜¤ìë§ˆì í˜„ì¬ ìƒíƒœ ë¡œê·¸
      // const before = {
      //   isCapturingRef: isCapturingRef.current,
      //   raf: animationFrameIdRef.current,
      //   encoding: encodingRef.current,
      //   frames: frameBufferRef.current.length,
      //   epoch: captureEpochRef.current,
      // };
      // console.log('[stopCapture] called', before);

      // 2) ì´ë¯¸ ë©ˆì¶°ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜
      if (!isCapturingRef.current) {
        console.warn('[stopCapture] already stopped â†’ []');
        return [];
      }

      // 3) ì—¬ê¸°ì„œ ìƒíƒœ ë‚´ë¦¬ê¸°/ì·¨ì†Œ/ë°˜í™˜
      isCapturingRef.current = false;
      setIsCapturing(false);

      if (animationFrameIdRef.current !== null) {
        cancelAnimationFrame(animationFrameIdRef.current);
        animationFrameIdRef.current = null;
      }

      const capturedFrames = frameBufferRef.current;

      console.log('[stopCapture] âœ… STOP', {
        frames: capturedFrames.length,
        raf: animationFrameIdRef.current,
        encoding: encodingRef.current,
        epoch: captureEpochRef.current,
      });

      return capturedFrames;
    }, []); // â† ì˜ì¡´ì„± ë¹„ì›Œì„œ ì•ˆì •í™”
  /**
   * í”„ë ˆì„ ìº¡ì²˜ ì‹œì‘
   */
  const startCapture = useCallback((startTime: number, endTime: number): void => {


  //     console.log('[startCapture] called', {
  //   isCapturingRef: isCapturingRef.current,
  //   videoReady: !!videoRef.current,
  //   audioReady: !!audioRef.current,
  //   canvasReady: !!canvasRef.current,
  // });
    // âœ… ì„¸ì´í”„í‹° ìŠ¤í†± ì¶”ê°€
  if (isCapturingRef.current) {
    console.warn('[startCapture] previous capture still active â†’ safe stop before new start');
    stopCapture();   // ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ ìº¡ì²˜ ì™„ì „íˆ ì¢…ë£Œ
  }
    // âœ… ìˆ˜ì •
    if (isCapturingRef.current || !videoRef.current || !audioRef.current || !canvasRef.current)
      {
        console.warn('âš ï¸  ìº¡ì²˜ ì‹œì‘ ì‹¤íŒ¨: ì´ë¯¸ ìº¡ì²˜ ì¤‘ì´ê±°ë‚˜ refê°€ ì—†ìŒ');
        return;
      } 
    const video = videoRef.current;
    const audio = audioRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');

    if (!ctx || video.readyState < 2) {
      console.warn('âš ï¸  ìº¡ì²˜ ì‹œì‘ ì‹¤íŒ¨: canvas ë˜ëŠ” video ì¤€ë¹„ ì•ˆ ë¨');
      return;
    }

    const now = audio.currentTime;
    // console.log('ğŸ¯ TIMING CHECK', {
    //   now: now.toFixed(3),
    //   startTime: startTime.toFixed(3),
    //   endTime: endTime.toFixed(3),
    //   guard: GAME_CONFIG.LATE_GUARD,
    //   diffToEnd: (endTime - now).toFixed(3),
    // });
    // ë„ˆë¬´ ëŠ¦ê²Œ ì‹œì‘í•˜ë ¤ëŠ” ê²½ìš° ê±´ë„ˆë›°ê¸°
    if (now > endTime - GAME_CONFIG.LATE_GUARD) {
      console.warn(`â­ ì„¸ê·¸ë¨¼íŠ¸ ê±´ë„ˆëœ€ (ëŠ¦ìŒ: ${now.toFixed(2)} > ${endTime.toFixed(2)})`);
      return;
    }

    // epoch ì¦ê°€(ìƒˆ ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘)
    captureEpochRef.current += 1;
    
    // âœ… ìˆ˜ì •
    isCapturingRef.current = true;  // ë¨¼ì € ref ì˜¬ë¦¼(ë£¨í”„ê°€ ì¦‰ì‹œ ë³´ê³  ì¸ì‹)
    setIsCapturing(true);           // UI í‘œì‹œ
    setFrameBuffer([]);             // UI ìƒíƒœ ì´ˆê¸°í™”
    frameBufferRef.current = [];    // ì‹¤ë°ì´í„° ì´ˆê¸°í™”
    
    captureStartTimeRef.current = performance.now();
    frameCountRef.current = 0;
    expectedFramesRef.current = calculateExpectedFrames(startTime, endTime, now);
    encodingRef.current = false;

  //   console.log('[startCapture] âœ… START', {
  //   epoch: captureEpochRef.current,
  //   expectedFrames: expectedFramesRef.current,
  //   canvasSize: { w: canvas.width, h: canvas.height },
  // });
    console.log(`ğŸ“¹ ìº¡ì²˜ ì‹œì‘ (ì˜ˆìƒ í”„ë ˆì„: ${expectedFramesRef.current})`);

    /**
     * requestAnimationFrame ê¸°ë°˜ ìº¡ì²˜ ë£¨í”„
     */
    const captureFrame = () => {
      // âœ… ìˆ˜ì •
      if (!isCapturingRef.current) return;

      const elapsed = performance.now() - captureStartTimeRef.current;
      const targetFrame = Math.floor(elapsed / GAME_CONFIG.FRAME_MS);

      // ë‹¤ìŒ í”„ë ˆì„ ì‹œê°„ê¹Œì§€ ëŒ€ê¸°
      if (
        frameCountRef.current < targetFrame &&
        !encodingRef.current &&
        video.readyState >= 2
      ) {
        encodingRef.current = true;
        frameCountRef.current++;

        // canvasì— video í”„ë ˆì„ ê·¸ë¦¬ê¸°
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        const epochAtSchedule = captureEpochRef.current;
        // Blobìœ¼ë¡œ ë³€í™˜
        canvas.toBlob(
          (blob) => {
            // @ts-ignore: suppress 'myEpoch' unused diagnostic
              const myEpoch = captureEpochRef.current; // ì½œë°± ì‹œì ì˜ epoch ì°¸ì¡°(ë¡œê·¸ìš©)
            if (!blob) {
              encodingRef.current = false;
              return;
            }

            
            // âœ… ì¶”ê°€: ì´ë¯¸ ìº¡ì²˜ê°€ ëë‚¬ë‹¤ë©´ ë¬´ì‹œ
            if (!isCapturingRef.current) {
              console.warn('[toBlob] late callback after stop â†’ ignore');
              encodingRef.current = false;
              return;
            }

              // âœ… ì¶”ê°€: ë‚´ epochì™€ í˜„ì¬ epochê°€ ë‹¤ë¥´ë©´ ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ì˜ ëŠ¦ì€ ì½œë°± â†’ ë¬´ì‹œ
            if (epochAtSchedule !== captureEpochRef.current) {
              console.warn('[toBlob] epoch mismatch â†’ ignore', { epochAtSchedule, current: captureEpochRef.current });
              encodingRef.current = false;
              return;
            }
            const frame: Frame = {
              img: blob,
              musicTime: audio.currentTime,
              captureTime: elapsed,
            };

         
          // âœ… ìˆ˜ì •
          frameBufferRef.current = [...frameBufferRef.current, frame]; // ì‹¤ë°ì´í„° ê°±ì‹ 
          setFrameBuffer(frameBufferRef.current);                      // UI ë™ê¸°í™”

          //   console.log('[toBlob] +frame', {
          //   epoch: myEpoch,
          //   count: frameBufferRef.current.length,
          //   frameCountRef: frameCountRef.current,
          //   expected: expectedFramesRef.current,
          //   encodingBusy: encodingRef.current,
          // });

          if (frameBufferRef.current.length >= expectedFramesRef.current) {
           // âœ… ìˆ˜ì •
            if (isCapturingRef.current) {
              console.log('[toBlob] reached expectedFrames â†’ stopCapture()');
              stopCapture(); }// í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ë„ë¡ ê°€ë“œ
          }

            encodingRef.current = false;
          },
          'image/jpeg',
          0.8
        );
      }

      // âœ… ìˆ˜ì •
      if (isCapturingRef.current) {
        animationFrameIdRef.current = requestAnimationFrame(captureFrame);
      }
    };

    requestAnimationFrame(() => {
  animationFrameIdRef.current = requestAnimationFrame(captureFrame);
});
  }, [videoRef, audioRef, canvasRef,stopCapture ]);




  return {
    isCapturing,
    frameBuffer,
    startCapture,
    stopCapture,
  };
};
